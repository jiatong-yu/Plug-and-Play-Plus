{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/nlp-jiatongy/miniconda3/envs/.venv-22fall/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import torch\n",
    "import logging\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "launched eval pipeline.\n"
     ]
    }
   ],
   "source": [
    "from model_util import load_model\n",
    "from data_util import load_data\n",
    "from eval import load_data_pair\n",
    "handlers = [logging.StreamHandler()]\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=handlers)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import eval_bleu, eval_simcse,eval_tfidf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support  \n",
    "gpt2-xl normal: 500 sample  \n",
    "gpt2-large normal: 800 sample  \n",
    "gpt2-medium normal: 800 sample  \n",
    "opt-1.3b normal: 500 sample  \n",
    "galactica-6.7b normal: 100 sample  \n",
    "  \n",
    "gpt2-xl adv: 400 sample  \n",
    "gpt2-large adv: 400 sample  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/16/2022 17:05:23 - INFO - __main__ -   loading data from baseline1/cc_news-output/var_len/gpt2-xl-300-adv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"gpt2-xl\"\n",
    "if MODEL_NAME in [\"galactica-1.3b\",\"galactica-6.7b\"]:\n",
    "    NORMAL_PATH = f\"baseline1/cc_news-output/{MODEL_NAME}-top-p\"\n",
    "else: \n",
    "    NORMAL_PATH = f\"baseline1/cc_news-output/var_len/{MODEL_NAME}-300-FINAL\"\n",
    "    ADV_PATH = f\"baseline1/cc_news-output/var_len/{MODEL_NAME}-300-adv\"\n",
    "    IN_CONTEXT_PATH = f\"baseline1/cc_news-output/var_len/{MODEL_NAME}-300-INCONTEXT\"\n",
    "generations,labels = load_data_pair(logger,ADV_PATH)\n",
    "print(len(generations))\n",
    "print(len(labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT2 xl normal path  \n",
    "interesting_idx = [12,24,108]  \n",
    "misaligned_idx = [48,49,]  \n",
    "hallu_idx = [73,]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_actual = \"Generation: \"+generations[2].split(sep=\"Generation:\")[1]\n",
    "lab_actual = \"Generation: \"+labels[2].split(sep=\"Generation: \")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/16/2022 16:41:59 - INFO - __main__ -   calculating bleu scores...\n",
      "12/16/2022 16:42:01 - INFO - __main__ -   bleu score: {'bleu': 0.07395018073983242, 'precisions': [0.37624281134217386, 0.14789084678780906, 0.11406577149233335, 0.10806173879161901], 'brevity_penalty': 0.45696195077137136, 'length_ratio': 0.5608036966688704, 'translation_length': 160322, 'reference_length': 285879}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.07395018073983242,\n",
       " 'precisions': [0.37624281134217386,\n",
       "  0.14789084678780906,\n",
       "  0.11406577149233335,\n",
       "  0.10806173879161901],\n",
       " 'brevity_penalty': 0.45696195077137136,\n",
       " 'length_ratio': 0.5608036966688704,\n",
       " 'translation_length': 160322,\n",
       " 'reference_length': 285879}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_simcse(logger,generations,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/16/2022 16:42:26 - INFO - __main__ -   calculating bleu scores...\n",
      "12/16/2022 16:42:29 - INFO - __main__ -   bleu score: {'bleu': 0.08180044273396, 'precisions': [0.34961905374832297, 0.1507218469753892, 0.12280282790290402, 0.11605161174481414], 'brevity_penalty': 0.4941376472283615, 'length_ratio': 0.5865305043946887, 'translation_length': 201997, 'reference_length': 344393}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.08180044273396,\n",
       " 'precisions': [0.34961905374832297,\n",
       "  0.1507218469753892,\n",
       "  0.12280282790290402,\n",
       "  0.11605161174481414],\n",
       " 'brevity_penalty': 0.4941376472283615,\n",
       " 'length_ratio': 0.5865305043946887,\n",
       " 'translation_length': 201997,\n",
       " 'reference_length': 344393}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_bleu(logger,generations,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "205e701fff26ee62ce6f380efaa542ebe8da0ba1ca78b8b8088a8b6bda57874a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 ('.venv-22fall')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
